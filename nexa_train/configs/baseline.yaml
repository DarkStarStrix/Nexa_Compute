project:
  slug: scientific_assistant
  name: Scientific Assistant

experiment:
  name: baseline
  output_dir: artifacts/runs
  tags:
    owner: training-team

data:
  dataset_name: synthetic
  batch_size: 64
  num_workers: 4
  preprocessing:
    num_features: 32
    num_classes: 4
    seed: 7

model:
  name: mlp_classifier
  parameters:
    input_dim: 32
    hidden_dims: [256, 128, 64]
    num_classes: 4
    dropout: 0.2

training:
  epochs: 10
  max_steps: null
  log_every_n_steps: 5
  gradient_clip_norm: 1.0
  optimizer:
    name: adamw
    lr: 0.0005
    weight_decay: 0.01
  scheduler:
    name: cosine
    args:
      t_max: 10
      early_stop_patience: 8
  distributed:
    backend: nccl
    world_size: 1
    num_nodes: 1
    gradient_accumulation_steps: 1
    mixed_precision: false
    seed: 123
  checkpoint:
    dir: artifacts/checkpoints
    monitor: val_loss
    mode: min
    save_top_k: 3
    save_every_n_epochs: 1
  logging:
    level: INFO
    log_dir: logs
    tensorboard: true

evaluation:
  metrics: [accuracy, f1, precision, recall]
  batch_size: 128
  save_predictions: true
  output_dir: artifacts/evaluation
