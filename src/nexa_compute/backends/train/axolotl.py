"""Axolotl training backend for NexaCompute."""

from __future__ import annotations

import copy
import hashlib
import json
import logging
import os
import subprocess
import sys
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Mapping, MutableMapping

import yaml

from ...core.artifacts import ArtifactMeta, create_artifact

LOGGER = logging.getLogger(__name__)

DEFAULT_MODULE = "axolotl.cli.train"

__all__ = [
    "AxolotlBackend",
    "render_config",
]


def _now_utc() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def _deep_merge(base: MutableMapping[str, object], updates: Mapping[str, object]) -> MutableMapping[str, object]:
    for key, value in updates.items():
        if isinstance(value, Mapping) and isinstance(base.get(key), Mapping):
            base[key] = _deep_merge(copy.deepcopy(base[key]), value)  # type: ignore[arg-type]
        else:
            base[key] = value  # type: ignore[assignment]
    return base


def render_config(recipe: Mapping[str, object] | None, overrides: Mapping[str, object]) -> MutableMapping[str, object]:
    """Return an Axolotl configuration by merging ``recipe`` and ``overrides``."""

    base = copy.deepcopy(recipe) if recipe else {}
    if not isinstance(base, MutableMapping):  # pragma: no cover - defensive
        base = {}  # type: ignore[assignment]
    return _deep_merge(base, dict(overrides))


@dataclass
class AxolotlBackend:
    """Wrapper around the Axolotl CLI."""

    recipe: Mapping[str, object] | None = None
    module: str = DEFAULT_MODULE

    def build_config(self, overrides: Mapping[str, object]) -> MutableMapping[str, object]:
        return render_config(self.recipe, overrides)

    def run(
        self,
        overrides: Mapping[str, object],
        *,
        artifact_dir: Path,
        env: Mapping[str, str] | None = None,
        dry_run: bool = False,
    ) -> ArtifactMeta:
        """Execute the Axolotl backend and return the produced artifact metadata."""

        artifact_dir = Path(artifact_dir)

        def _producer(tmp_dir: Path) -> ArtifactMeta:
            config = self.build_config(overrides)
            output_dir = tmp_dir / "checkpoint"
            config["output_dir"] = str(output_dir)
            config_path = tmp_dir / "axolotl_config.yaml"
            with config_path.open("w", encoding="utf-8") as handle:
                yaml.safe_dump(config, handle, sort_keys=False)

            command = [
                "accelerate",
                "launch",
                "-m",
                self.module,
                str(config_path),
            ]
            env_vars = os.environ.copy()
            if env:
                env_vars.update({str(k): str(v) for k, v in env.items()})

            if dry_run:
                LOGGER.info("[axolotl] dry run :: %s", " ".join(command))
            else:
                try:
                    subprocess.run(command, check=True, env=env_vars)
                except FileNotFoundError:
                    fallback = [sys.executable, "-m", self.module, str(config_path)]
                    LOGGER.warning("[axolotl] accelerate not found; falling back to %s", fallback)
                    subprocess.run(fallback, check=True, env=env_vars)

            if not output_dir.exists():
                LOGGER.warning("[axolotl] checkpoint directory missing; generating placeholder at %s", output_dir)
                output_dir.mkdir(parents=True, exist_ok=True)
                (output_dir / "README.txt").write_text("Placeholder checkpoint generated by stub backend\n")

            command_path = tmp_dir / "command.json"
            command_payload = {
                "timestamp": _now_utc(),
                "command": command,
                "module": self.module,
                "dry_run": dry_run,
            }
            command_path.write_text(json.dumps(command_payload, indent=2))

            payload_hash = hashlib.sha256()
            total_bytes = 0
            for file_path in tmp_dir.rglob("*"):
                if file_path.is_file():
                    data = file_path.read_bytes()
                    payload_hash.update(data)
                    total_bytes += len(data)

            metadata = ArtifactMeta(
                kind="checkpoint",
                uri=str(artifact_dir.resolve()),
                hash=f"sha256:{payload_hash.hexdigest()}",
                bytes=total_bytes,
                created_at=_now_utc(),
                inputs=[str(overrides.get("dataset"))] if overrides.get("dataset") else [],
                labels={
                    "backend": "axolotl",
                    "module": self.module,
                },
            )
            return metadata

        return create_artifact(artifact_dir, _producer)
